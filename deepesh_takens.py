# -*- coding: utf-8 -*-
"""Abarbanel-22-10-2021.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uTEuPwrFv2ErqPaX6rtXc-EHlTgSvN73

# Analysis from "The analysis of observed chaotic data in physical systems"
### Most of the analysis will be done for 2 systems- Lorenz system(xl,yl,zl) and Henon map(xh,yh)
"""

import numpy as np
#import matplotlib.pyplot as plt
# %matplotlib inline
#from mpl_toolkits import mplot3d
takens=open(r"Takens-Embedding.txt","a")
"""Generating Lorenz Attractor Points"""

s=10.0
b=8.0/3.0
gamma=28.0

def lorenz(r,t):
    x=r[0]
    y=r[1]
    z=r[2]
    fx=10*(y-x)
    fy=28*x-y-x*z
    fz=x*y-b*z
    return np.array([fx,fy,fz])

a=0
tf=200
Nl=20000
h=(tf-a)/Nl
tl=np.arange(a,tf,h)

xl=np.ones(Nl+1)
yl=np.ones(Nl+1)
zl=np.ones(Nl+1)
#initial condition
r=np.array([1.,1.,1.])
i=0
for t in tl:
    k1=h*lorenz(r,t)
    k2=h*lorenz(r+0.5*k1,t+0.5*h)
    k3=h*lorenz(r+0.5*k2,t+0.5*h)
    k4=h*lorenz(r+k3,t+h)
    r+= (k1+2*k2+2*k3+k4)/6
    xl[i]=r[0]
    yl[i]=r[1]
    zl[i]=r[2]
    i=i+1
xl,yl,zl=xl[5000:],yl[5000:],zl[5000:]
Nl=15000

#fig = plt.figure()
#ax = fig.gca(projection='3d')
#ax.scatter(xl,yl,zl, s=1.5)
#plt.show()

"""Generating Henon Attractor points"""

a=1.4
b=0.3
Nh=5000
xh=np.zeros(Nh)
yh=np.zeros(Nh)
def Henon(x,y):
    for i in range(Nh-1):
        x[i+1]=1-a*x[i]**2+y[i]
        y[i+1]=b*x[i]
    return x,y

xh, yh=Henon(xh, yh)
xh,yh=xh[1000:],yh[1000:]
Nh=4000
#plt.scatter(xh,yh,s=1.5 )

#plt.show()

"""**Using Mutual Information(MI) as a tool to find optimal time delay**. Here, we use the minima for flows and the time when MI reaches 20% of the initial value for maps."""

def shannon(x):
    if np.sum(x)!=0:
        x_norm=x/np.sum(x)
        x_norm=x_norm[np.nonzero(x_norm)]
        H=-np.sum(x_norm*np.log2(x_norm))
    else:
        H=1
    return(H)

def MIlorenz(tau, x=xl,bins=20):
    tau=int(100*tau) #This line won't be used for Henon attractor 
    ami=0
    p_a=np.histogram(x, bins)[0] #convert x into a probability distribution
    xtau=np.roll(x,tau) #tau delayed version of x
    xtau=xtau[:-tau]
    p_b=np.histogram(xtau,bins)[0]
    x=x[:-tau] #slicing to get only tau elements

    p_ab=np.histogram2d(x,xtau,bins)[0]
    ami=shannon(p_a)+shannon(p_b)-shannon(p_ab)
    return ami

taum=tl[:200]
MIL=np.zeros(200)
for t in range(len(taum)):
    MIL[t]=MIlorenz(taum[t])
for t in range(len(taum)-1):    
  midiff=MIlorenz(taum[t+1])-MIlorenz(taum[t])
  midiff=midiff/h
  if midiff>0:
    
    Tlorenz=taum[t]
    break
takens.write("The delay for Lorenz map is "+ str(Tlorenz)+"\n")
#plt.plot(taum,MIL)
#plt.xlabel('Time Delay')
#plt.ylabel('Mutual Information')
#plt.savefig('image.jpg')
#plt.show()
Tlorenz=int(Tlorenz*100)


def MIhenon(tau,x=xh,bins=10):
    ami=0
    p_a=np.histogram(x, bins)[0]
    
    p_a=p_a #convert x into a probability distribution
    xtau=np.roll(x,tau) #tau delayed version of x
    xtau=xtau[:-tau]
    p_b=np.histogram(xtau,bins)[0]
    x=x[:-tau] #slicing to get only tau elements

    p_ab=np.histogram2d(x,xtau,bins)[0]
    ami=shannon(p_a)+shannon(p_b)-shannon(p_ab)

    return ami

taum=np.arange(40)
Minit=MIhenon(0)
for t in taum:
    
    if MIhenon(t)<=Minit/5:
      Thenon=t
      break
takens.write("The time delay for Henon map can be "+ str(Thenon)+"\n")

"""Thus, we get the time delay T for Lorenz model as Tlorenz=0.17 and T for Henon map as Thenon=4 \\
**Choosing the embedding dimension through FNN method**
"""

rt=20
fnnhenon=np.ones(5) #taking 5 as max dimensions
for dim in range(1,6):
  col=1000-dim
  mhenon=np.zeros((dim,col))
  for i in range(col):
    mhenon[:,i]=np.array([xh[i+j] for j in range(dim)])
    dist=np.linalg.norm(mhenon-mhenon[:,i].reshape((dim,1)), axis=0)
    mindist=20000
    for k in range(col):
      if k==i:
        continue
      else:
        if dist[k]<mindist:
          min=k
          mindist=dist[k]
    if np.abs((xh[i+(dim+1)]-xh[min+(dim+1)])/mindist)>rt:
      fnnhenon[dim-1]+=1
  fnnhenon[dim-1]=fnnhenon[dim-1]/(col)*100
for i in range(1,6):
    if fnnhenon[i]<0.005*fnnhenon[i-1]:
        takens.write("The embedding dimension of Henon Map is "+ str(i+1)+"\n")
        break

#~6s
fnnlorenz=np.zeros(5) #taking 5 as max dimensions
for dim in range(1,6):
  col=2000-dim*Tlorenz
  mlorenz=np.zeros((dim,col))
  for i in range(col):
    mlorenz[:,i]=np.array([xl[i+j*Tlorenz] for j in range(dim)])
    dist=np.linalg.norm(mlorenz-mlorenz[:,i].reshape((dim,1)), axis=0)
    mindist=20000
    for k in range(col):
      if k==i:
        continue
      else:
        if dist[k]<mindist:
          min=k
          mindist=dist[k]
    if np.abs((xl[i+(dim+1)*Tlorenz]-xl[min+(dim+1)*Tlorenz])/mindist)>rt:
      fnnlorenz[dim-1]+=1
  fnnlorenz[dim-1]=fnnlorenz[dim-1]/(col)*100
for i in range(5):
    if fnnlorenz[i]==0.0:
        takens.write("Embedding dimension of lorenz-63 model is "+str(i+1)+"\n")
        break

#plt.plot(np.arange(1,6), fnnhenon)
#plt.xlabel('Embedding dimension')
#plt.ylabel('Percentage of false nearest neighbours')
#plt.savefig('Henonfnn.jpg')
#plt.show()

#plt.plot(np.arange(1,6), fnnlorenz)
#plt.xlabel('Embedding dimension')
#plt.ylabel('Percentage of false nearest neighbours')
#plt.savefig('lorenzfnn.jpg')
#plt.show()

"""Now, we try to reconstruct the attractors in 3 and 2 dimensions respectively, then we will try to see how close we are to the original attractor."""

#original attractor
lorenzorig=np.zeros((Nl+1,3))
lorenzorig[:,0]=xl
lorenzorig[:,1]=yl
lorenzorig[:,2]=zl
#reconstructed attractor
lorenzrecon=np.zeros((15000-2*Tlorenz,3))
lorenzrecon[:,0]=xl[:-2*Tlorenz-1]
lorenzrecon[:,1]=xl[Tlorenz:-Tlorenz-1]
lorenzrecon[:,2]=xl[2*Tlorenz]

Thenon=1
henonorig=np.zeros((Nh,2),float)
henonorig[:,0]=xh
henonorig[:,1]=yh

henonrecon=np.zeros((Nh-Thenon,2))
henonrecon[:,0]=xh[:-Thenon]
henonrecon[:,1]=xh[Thenon:]

"""Meausures of closeness
1. Appearance of the reconstructed trajectory: We see how much the reconstruction looks like the original attractor. Not a very good measure.
"""

#fig = plt.figure()
#ax = fig.gca(projection='3d')
#ax.scatter(lorenzrecon[:,0],lorenzrecon[:,1],lorenzrecon[:,2], s=1.5)
#plt.savefig('Lorenzrecon.jpg')
#plt.show()

#plt.scatter(henonrecon[:,0],henonrecon[:,1])
#plt.savefig('henonrecon.jpg')
#plt.show()

"""This looks slightly close but it is pretty obvious that it is not the right way to check our embedding because of the vagueness of such a metric. Thus, we look for other ways.

"""


takens.write("Henon gives a better embedding if time delay is taken to be 1 instead of the value found by mutual information(4). Same issue found using pointwise comparison too.\n")


"""


2. Pointwise Comparison / Procrustes transform: We can only apply this transform as the original attractor and the final time delayed reconstruction are of the same number of dimensions. Procrustes transform applies translation, rotation, reflection to align the two sets of data we have, and then we find the $d_E$ dimensional Euclidean distance divided by the the number of points to normalise the distance.
"""

from scipy.spatial import procrustes

lorenzorig=lorenzorig[:15000-2*Tlorenz,:]
mtl1,mtl2,eudl=procrustes(lorenzorig,lorenzrecon)
eudl=eudl/(len(lorenzorig))
takens.write("Pointwise distance for Lorenz model reconstruction= "+str(eudl)+"\n")

henonorig=henonorig[:Nh-Thenon,:]
mth1,mth2,eudh=procrustes(henonorig,henonrecon)
eudh=eudh/(len(henonorig))
takens.write("Pointwise distance for Henon map reconstruction= "+str(eudh)+"\n")

"""We see that the distance in both the cases is a small number as compared to the lengths of the attractors(~50 for Lorenz model and ~1 for Henon map). 
3. Local neighborhoods: We see that this is an algorithm that takes a lot of time, so we have taken very less number of points in this implementation.
"""

lor=lorenzorig[-3000:,:]
lre=lorenzrecon[-3000:,:]
def kappa(k,y,yhat): 
  col=np.shape(y)[0]  #no of data points
  dim=np.shape(y)[1]  #no of dimensions
  kappa=np.zeros(col)
  for i in range(col):
    dist=np.linalg.norm(y-(y[i,:].reshape(1,dim)), axis=1)
    distval=np.argsort(dist)[:k]
    dist2=np.linalg.norm(yhat-(yhat[i,:].reshape(1,dim)),axis=1)
    dist2val=np.argsort(dist2)[:k]
    kappa[i]=len(np.intersect1d(distval,dist2val))
  return np.mean(kappa)

kvl=np.arange(4000)
kpl=np.zeros(4000)
for i in range(len(kpl)):
  kpl[i]=kappa(kvl[i],henonorig,henonrecon)
nhen=np.shape(henonorig)[0]
hypgeo=kvl*kvl/np.shape(henonorig)[0]
#plt.plot(kvl,kpl, label="Local Neighborhood of Reconstructed Henon map")
#plt.plot(kvl,hypgeo, label="Random Distribution")
#plt.plot(kvl,kvl, label="Perfect Embedding")
#plt.xlabel("k- values")
#plt.ylabel("kappa(k)")
#plt.legend()
#plt.savefig('Henonkappa.jpg')
#plt.show()
hennorm=np.sum(kpl)*2/(nhen*(nhen+1))
takens.write("Local Neighbourhoods:\n")
takens.write("henon reconstruction accuracy: "+ str(hennorm)+"\n")
takens.write("random case accuracy: "+ str(np.sum(2*hypgeo/(nhen*(nhen+1))))+"\n")

kvl=np.arange(3000)
kpl=np.zeros(3000)
for i in range(len(kpl)):
  kpl[i]=kappa(kvl[i],lor,lre)
nlor=np.shape(lor)[0]
hypgeo=kvl*kvl/np.shape(lor)[0]
#plt.plot(kvl,kpl, label="Local Neighborhood of Reconstructed Lorenz map")
#plt.plot(kvl,hypgeo, label="Random Distribution")
#plt.plot(kvl,kvl, label="Perfect Embedding")
#plt.xlabel("k- values")
#plt.ylabel("kappa(k)")
#plt.legend()
#plt.savefig('lorenzkappa.jpg')
#plt.show()
lornorm=np.sum(kpl)*2/(nlor(nlor+1))
takens.write("reconstructed lorenzmodel accuracy: "+str(lornorm)+"\n")
takens.write("random case accuracy: "+ str(np.sum(2*hypgeo/(nlor*(nlor+1))))+"\n")

"""**Lorenz-96 model**  We now look at higher dimensional strange attractors like the Lorenz96  model. 
Code taken from wikipedia"""

from scipy.integrate import odeint
N=5
F=8.0
def L96(x,t):
  d=np.zeros(N)
  for i in range(N):
    d[i] = (x[(i + 1) % N] - x[i - 2]) * x[i - 1] - x[i] + F
  return d
x0 = F * np.ones(N)  # Initial state (equilibrium)
x0[0] +=2  # Add small perturbation to the first variable
t96 = np.arange(0.0, 40.0, 0.01)
L96orig = odeint(L96, x0, t96)
x96=L96orig[:,0]
np.shape(L96orig)

taum=t96[:200]
MIL=np.zeros(200)
for t in range(len(taum)):
    MIL[t]=MIlorenz(taum[t],x96)
for t in range(len(taum)-1):    
  midiff=MIlorenz(taum[t+1],x96)-MIlorenz(taum[t],x96)
  midiff=midiff/h
  if midiff>0:
    
    T96=taum[t]
    break
takens.write("The delay for Lorenz96,n=5 map is "+ str(T96)+"\n")
#plt.plot(taum,MIL)
#plt.xlabel('Time Delay')
#plt.ylabel('Mutual Information')
#plt.savefig('img12.jpg')
#plt.show()
T96=int(T96*100)

fnn96=np.zeros(10) #taking 2N=10 as max dimensions
for dim in range(1,11):
  col=2000-dim*T96
  m96=np.zeros((dim,col))
  for i in range(col):
    m96[:,i]=np.array([x96[i+j*T96] for j in range(dim)])
    dist=np.linalg.norm(m96-m96[:,i].reshape((dim,1)), axis=0)
    mindist=20000
    for k in range(col):
      if k==i:
        continue
      else:
        if dist[k]<mindist:
          min=k
          mindist=dist[k]
    if np.abs((x96[i+(dim+1)*T96]-x96[min+(dim+1)*T96])/mindist)>rt:
      fnn96[dim-1]+=1
  fnn96[dim-1]=fnn96[dim-1]/(col)*100

#plt.plot(np.arange(1,11),fnn96)
for i in range(len(fnn96)):
  if fnn96[i]==0:
    d96=i+1
    takens.write("The embedding dimension for Lorenz96, n=5 model is "+str(d96)+"\n")
    break
#plt.show()

indexes = np.arange(0,d96,1)*T96
L96recon5=np.array([x96[indexes +i] for i in range(len(x96)-(d96-1)*T96)])

"""**Doing the same analysis for n=4**"""

N=4
x0 = F * np.ones(N)  # Initial state (equilibrium)
x0[0] +=2  # Add small perturbation to the first variable
t96 = np.arange(0.0, 30.0, 0.01)
L96orig = odeint(L96, x0, t96)
x96=L96orig[:,0]
np.shape(L96orig)

taum=t96[:200]
MIL=np.zeros(200)
for t in range(len(taum)):
    MIL[t]=MIlorenz(taum[t],x96)
for t in range(len(taum)-1):    
  midiff=MIlorenz(taum[t+1],x96)-MIlorenz(taum[t],x96)
  midiff=midiff/h
  if midiff>0:
    
    T96=taum[t]
    break
takens.write("The delay for L96,n=4 model is"+ str(T96)+"\n")
#plt.plot(taum,MIL)
#plt.xlabel('Time Delay')
#plt.ylabel('Mutual Information')
#plt.savefig('img12.jpg')
#plt.show()
T96=int(T96*100)

fnn96=np.zeros(8) #taking 2N=8 as max dimensions
for dim in range(1,9):
  col=2000-dim*T96
  m96=np.zeros((dim,col))
  for i in range(col):
    m96[:,i]=np.array([x96[i+j*T96] for j in range(dim)])
    dist=np.linalg.norm(m96-m96[:,i].reshape((dim,1)), axis=0)
    mindist=20000
    for k in range(col):
      if k==i:
        continue
      else:
        if dist[k]<mindist:
          min=k
          mindist=dist[k]
    if np.abs((x96[i+(dim+1)*T96]-x96[min+(dim+1)*T96])/mindist)>rt:
      fnn96[dim-1]+=1
  fnn96[dim-1]=fnn96[dim-1]/(col)*100

#plt.plot(np.arange(1,9),fnn96)

for i in range(len(fnn96)):
  if fnn96[i]==0:
    d96=i+1
    takens.write("The embedding dimension for Lorenz96, n=5 model is "+str(d96)+"\n")
    break
#plt.show()

"""**Same analysis for N=6**"""

N=6
x0 = F * np.ones(N)  # Initial state (equilibrium)
x0[0] +=2  # Add small perturbation to the first variable
t96 = np.arange(0.0, 40.0, 0.01)
L96orig = odeint(L96, x0, t96)
x96=L96orig[:,0]
np.shape(L96orig)

taum=t96[:200]
MIL=np.zeros(200)
for t in range(len(taum)):
    MIL[t]=MIlorenz(taum[t],x96)
for t in range(len(taum)-1):    
  midiff=MIlorenz(taum[t+1],x96)-MIlorenz(taum[t],x96)
  midiff=midiff/h
  if midiff>0:
    
    T96=taum[t]
    break
takens.write("The delay for L96,n=6 model is"+ str(T96)+"\n")
#plt.plot(taum,MIL)
#plt.xlabel('Time Delay')
#plt.ylabel('Mutual Information')
#plt.savefig('img12.jpg')
#plt.show()
T96=int(T96*100)

fnn96=np.zeros(12) #taking 2N=12 as max dimensions
for dim in range(1,11):
  col=2000-dim*T96
  m96=np.zeros((dim,col))
  for i in range(col):
    m96[:,i]=np.array([x96[i+j*T96] for j in range(dim)])
    dist=np.linalg.norm(m96-m96[:,i].reshape((dim,1)), axis=0)
    mindist=20000
    for k in range(col):
      if k==i:
        continue
      else:
        if dist[k]<mindist:
          min=k
          mindist=dist[k]
    if np.abs((x96[i+(dim+1)*T96]-x96[min+(dim+1)*T96])/mindist)>rt:
      fnn96[dim-1]+=1
  fnn96[dim-1]=fnn96[dim-1]/(col)*100

#plt.plot(np.arange(1,13),fnn96)
for i in range(len(fnn96)):
  if fnn96[i]==0:
    d96=i+1
    takens.write("The embedding dimension for Lorenz96, n=5 model is "+str(d96)+"\n")
    break
#plt.show()